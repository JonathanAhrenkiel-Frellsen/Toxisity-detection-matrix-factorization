{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization:\n",
    "  def __init__(self, R, k, lr=.0003, l2=.04, seed=777):\n",
    "    self.R = tf.convert_to_tensor(R, dtype=tf.float32)\n",
    "    self.mask = tf.not_equal(self.R, 0)\n",
    "    self.m, self.n = R.shape\n",
    "    self.k = k\n",
    "    self.lr = lr\n",
    "    self.l2 = l2\n",
    "    self.tol = .001\n",
    "    # Initialize trainable weights.\n",
    "    self.weight_init = tf.random_normal_initializer(seed=seed)\n",
    "    self.P = tf.Variable(self.weight_init((self.m, self.k)))\n",
    "    self.Q = tf.Variable(self.weight_init((self.n, self.k)))\n",
    "\n",
    "  def loss(self):\n",
    "    raise NotImplementedError\n",
    "\n",
    "  def grad_update(self):\n",
    "    with tf.GradientTape() as t:\n",
    "      t.watch([self.P, self.Q])\n",
    "      self.current_loss = self.loss()\n",
    "    gP, gQ = t.gradient(self.current_loss, [self.P, self.Q])\n",
    "    self.P.assign_sub(self.lr * gP)\n",
    "    self.Q.assign_sub(self.lr * gQ)\n",
    "\n",
    "  def train(self, n_epoch=5000):\n",
    "    for epoch in range(n_epoch):\n",
    "      self.grad_update()\n",
    "      if self.current_loss < self.tol:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryMF(MatrixFactorization):\n",
    "  def train(self, n_epoch=5000):\n",
    "    # Cast 1/-1 as binary encoding of 0/1.\n",
    "    self.labels = tf.cast(tf.not_equal(tf.boolean_mask(self.R, self.mask), -1), dtype=tf.float32)\n",
    "    for epoch in range(n_epoch):\n",
    "      self.grad_update()\n",
    "\n",
    "  # The implementation is far from optimized since we don't need the product of entire P'Q.\n",
    "  # We only need scores for non-missing entries.\n",
    "  # The code is hence for educational purpose only.\n",
    "  def loss(self):\n",
    "    \"\"\"Cross entropy loss.\"\"\"\n",
    "    logits = tf.boolean_mask(tf.matmul(self.P, self.Q, transpose_b=True), self.mask)\n",
    "    logloss = tf.nn.sigmoid_cross_entropy_with_logits(labels=self.labels, logits=logits)\n",
    "    mlogloss = tf.reduce_mean(logloss)\n",
    "    l2_norm = tf.reduce_sum(self.P**2) + tf.reduce_sum(self.Q**2)\n",
    "    return mlogloss + self.l2 * l2_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  1  0  0  0 -1  0 -1  0]\n",
      " [ 0  1  1  0 -1  0  0  0  1 -1]\n",
      " [ 0  0 -1  0  0  0 -1  0  0  0]\n",
      " [-1  0 -1  1  0 -1 -1  0  1  0]\n",
      " [ 0 -1  1  0  0  0 -1  0  1  0]]\n"
     ]
    }
   ],
   "source": [
    "# Make missing more prevail.\n",
    "responses = [-1, 0, 1]\n",
    "p = np.array([1, 5, 1])\n",
    "m = 5\n",
    "n = 10\n",
    "\n",
    "# A binary response matrix.\n",
    "b_ratings = np.random.choice(responses, size=m*n, p=p / p.sum()).reshape((m, n))\n",
    "print(b_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We increase the learning a bit since logloss has a very different scale than squared error.\n",
    "# For the same reason we decrease the L2 coefficient.\n",
    "bmf_model = BinaryMF(b_ratings, k=3, lr=.03, l2=.0001)\n",
    "bmf_model.train()\n",
    "\n",
    "b_predictions = tf.sigmoid(tf.matmul(bmf_model.P, bmf_model.Q, transpose_b=True)).numpy()\n",
    "\n",
    "b_mask = np.zeros_like(b_ratings)\n",
    "b_mask[b_ratings.nonzero()] = 1\n",
    "\n",
    "print(np.round(b_predictions * b_mask, 2)) # Check prediction on training entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit4727285c9b6c458095896ca6e60bc8a4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
